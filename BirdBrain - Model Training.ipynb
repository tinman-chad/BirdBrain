{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976cfb9d",
   "metadata": {},
   "source": [
    "# BirdBrain Data Wrangling and EDA\n",
    "\n",
    "## Data Source:\n",
    "ImageNet for transfer learning https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/description\n",
    "\n",
    "Kaggle Dataset: https://www.kaggle.com/gpiosenka/100-bird-species\n",
    "\n",
    "## Problem Statement:\n",
    "How can we identify the images of birds and the bird species with increasing photograph sets\n",
    "produced by the current bird camera and the 5 to be added to the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ff05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5c1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9105478188730521232\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "from os.path import exists\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import Any, List, Tuple, Union\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage.util import compare_images\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L, EfficientNetV2S, EfficientNetV2B0\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "import pickle\n",
    "\n",
    "#Use this to check if the GPU is configured correctly\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62dc63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "PROJECT_DATA_PATH = './Data/'\n",
    "#image expected size\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1afab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def imageSizedCorrectly(expectedHeight, expectedWidth, imagedata):\n",
    "    if imagedata.shape[0] == expectedHeight and imagedata.shape[1] == expectedWidth and imagedata.shape[2] > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getImageData(imagePath):\n",
    "    if exists(imagePath):\n",
    "        return io.imread(imagePath)\n",
    "\n",
    "def loadFilePointers(csvPath, dataset):\n",
    "    if not exists(csvPath):\n",
    "        raise Exception('File Not Found: ' + csvPath)\n",
    "    csv = pd.read_csv(csvPath)\n",
    "    return csv[csv[\"data set\"] == dataset]\n",
    "    \n",
    "def showDuplicateImages(set1ImagePaths, set2ImagePaths):\n",
    "    for idx in range(0, len(set1ImagePaths)):\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = fig.add_subplot(idx+1, idx+2, 1)\n",
    "        imgplot1 = plt.imshow(mpimg.imread(set1ImagePaths[idx]))\n",
    "        ax1.set_title(set1ImagePaths[idx])\n",
    "        ax2 = fig.add_subplot(idx+1, idx+2, 2)\n",
    "        imgplot2 = plt.imshow(mpimg.imread(set2ImagePaths[idx]))\n",
    "        ax2.set_title(set2ImagePaths[idx])\n",
    "        plt.show()\n",
    "        \n",
    "def remove_bad_images(folder_path):\n",
    "    num_skipped = 0\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "            print(f'Removed: {fpath}')\n",
    "    if num_skipped > 0:\n",
    "        print(f'Total Removed: {num_skipped}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b555535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"train\"):\n",
    "    for subdir in dirs:\n",
    "        remove_bad_images(os.path.join(PROJECT_DATA_PATH + \"train\", subdir))\n",
    "        \n",
    "for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"valid\"):\n",
    "    for subdir in dirs:\n",
    "        remove_bad_images(os.path.join(PROJECT_DATA_PATH + \"valid\", subdir))\n",
    "\n",
    "for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"test\"):\n",
    "    for subdir in dirs:\n",
    "        remove_bad_images(os.path.join(PROJECT_DATA_PATH + \"test\", subdir))\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1af7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47332 files belonging to 325 classes.\n",
      "Found 1625 files belonging to 325 classes.\n",
      "Train has 325 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PROJECT_DATA_PATH + \"train\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PROJECT_DATA_PATH + \"valid\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "num_classes = train_ds.element_spec[1].shape[1]\n",
    "print(f'Train has {num_classes} classes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df12d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    \"\"\"Redirect stderr to stdout, optionally print stdout to a file, and \n",
    "    optionally force flushing on both stdout and the file.\"\"\"\n",
    "\n",
    "    def __init__(self, file_name: str = None, file_mode: str = \"w\", \\\n",
    "                 should_flush: bool = True):\n",
    "        self.file = None\n",
    "\n",
    "        if file_name is not None:\n",
    "            self.file = open(file_name, file_mode)\n",
    "\n",
    "        self.should_flush = should_flush\n",
    "        self.stdout = sys.stdout\n",
    "        self.stderr = sys.stderr\n",
    "\n",
    "        sys.stdout = self\n",
    "        sys.stderr = self\n",
    "\n",
    "    def __enter__(self) -> \"Logger\":\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n",
    "        self.close()\n",
    "\n",
    "    def write(self, text: str) -> None:\n",
    "        \"\"\"Write text to stdout (and a file) and optionally flush.\"\"\"\n",
    "        if len(text) == 0: \n",
    "            return\n",
    "\n",
    "        if self.file is not None:\n",
    "            self.file.write(text)\n",
    "\n",
    "        self.stdout.write(text)\n",
    "\n",
    "        if self.should_flush:\n",
    "            self.flush()\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        \"\"\"Flush written text to both stdout and a file, if open.\"\"\"\n",
    "        if self.file is not None:\n",
    "            self.file.flush()\n",
    "\n",
    "        self.stdout.flush()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Flush, close possible files, and remove stdout/stderr mirroring.\"\"\"\n",
    "        self.flush()\n",
    "\n",
    "        # if using multiple loggers, prevent closing in wrong order\n",
    "        if sys.stdout is self:\n",
    "            sys.stdout = self.stdout\n",
    "        if sys.stderr is self:\n",
    "            sys.stderr = self.stderr\n",
    "\n",
    "        if self.file is not None:\n",
    "            self.file.close()\n",
    "\n",
    "\n",
    "class MyModelCheckpoint(ModelCheckpoint):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    super().on_epoch_end(epoch,logs)\\\n",
    "    \n",
    "    print(f'Epoch: {epoch}')\n",
    "    if logs == None:\n",
    "        logs = {'val_loss': 1.0}\n",
    "        \n",
    "    print(logs)\n",
    "    \n",
    "    # Also save the optimizer state\n",
    "    filepath = self._get_file_path(epoch, logs)\n",
    "    filepath = filepath.rsplit( \".\", 1 )[ 0 ] \n",
    "    filepath += \".pkl\"\n",
    "\n",
    "    with open(filepath, 'wb') as fp:\n",
    "      pickle.dump(\n",
    "        {\n",
    "          'opt': model.optimizer.get_config(),\n",
    "          'epoch': epoch+1\n",
    "         # Add additional keys if you need to store more values\n",
    "        }, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('\\nEpoch %05d: saving optimizaer to %s' % (epoch + 1, filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bcedbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "#model building\n",
    "def make_model(input_shape, num_classes):\n",
    "    base = EfficientNetV2B0(weights=\"imagenet\", include_top=False, input_shape=input_shape, classifier_activation=\"softmax\") #keras.Input(shape=input_shape)\n",
    "    model = models.Sequential()\n",
    "    model.add(base)\n",
    "    model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "    #model.add(data_augmentation)\n",
    "    #avoid overfitting\n",
    "    model.add(layers.Dropout(0.2, name=\"dropout_out\"))\n",
    "    # Set NUMBER_OF_CLASSES to the number of your final predictions.\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"fc_out\"))\n",
    "    base.trainable = False\n",
    "    return 0, model, keras.optimizers.Adam(1e-3).get_config()\n",
    "\n",
    "def load_model_data(model_path, opt_path):\n",
    "    model = load_model(model_path)\n",
    "    with open(opt_path, 'rb') as fp:\n",
    "      d = pickle.load(fp)\n",
    "      epoch = d['epoch']\n",
    "      opt = d['opt']\n",
    "      return epoch, model, opt\n",
    "    \n",
    "def train_model(model, initial_epoch=0, max_epochs=50):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    callbacks = [\n",
    "        MyModelCheckpoint(\n",
    "            os.path.join(PROJECT_DATA_PATH + 'models/', 'model-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "            monitor='val_loss',verbose=1),\n",
    "    ]\n",
    "    \n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=max_epochs,\n",
    "        initial_epoch = initial_epoch,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_ds,\n",
    "    )\n",
    "\n",
    "    #score = model.evaluate(x_test, y_test, verbose=0, callbacks=cb)\n",
    "    #print('Test loss: {}'.format(score[0]))\n",
    "    #print('Test accuracy: {}'.format(score[1]))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "696a2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(PROJECT_DATA_PATH + \"models\"):\n",
    "    for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"models\"):\n",
    "        for file in files:\n",
    "            print(file)\n",
    "else:\n",
    "    os.mkdir(PROJECT_DATA_PATH + \"models\")\n",
    "\n",
    "epoch, model, opt = make_model(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), num_classes=num_classes)\n",
    "#epoch, model, opt = load_model_data(model_path, opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7539a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam.from_config(opt),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a245e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "if not exists(PROJECT_DATA_PATH + \"logs\"):\n",
    "    os.mkdir(PROJECT_DATA_PATH + \"logs\")\n",
    "    \n",
    "with Logger(os.path.join(PROJECT_DATA_PATH + 'logs', 'log.txt')):\n",
    "    train_model(model, initial_epoch=epoch, max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce23def",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    PROJECT_DATA_PATH + \"test/BELTED KINGFISHER/4.jpg\", target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "print(\n",
    "    \"This image is %.2f percent cat and %.2f percent dog.\"\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
