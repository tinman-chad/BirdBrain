{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976cfb9d",
   "metadata": {},
   "source": [
    "# BirdBrain Data Wrangling and EDA\n",
    "\n",
    "## Data Source:\n",
    "ImageNet for transfer learning https://www.kaggle.com/c/imagenet-object-localization-challenge/overview/description\n",
    "\n",
    "Kaggle Dataset: https://www.kaggle.com/gpiosenka/100-bird-species\n",
    "\n",
    "## Problem Statement:\n",
    "How can we identify the images of birds and the bird species with increasing photograph sets\n",
    "produced by the current bird camera and the 5 to be added to the network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34ff05e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5c1358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9105478188730521232\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "from os.path import exists\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import Any, List, Tuple, Union\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage.util import compare_images\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetV2L, EfficientNetV2S, EfficientNetV2B0\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint\n",
    "import pickle\n",
    "\n",
    "#Use this to check if the GPU is configured correctly\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b62dc63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "PROJECT_DATA_PATH = './Data/'\n",
    "#image expected size\n",
    "IMAGE_HEIGHT = 224\n",
    "IMAGE_WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1afab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def imageSizedCorrectly(expectedHeight, expectedWidth, imagedata):\n",
    "    if imagedata.shape[0] == expectedHeight and imagedata.shape[1] == expectedWidth and imagedata.shape[2] > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getImageData(imagePath):\n",
    "    if exists(imagePath):\n",
    "        return io.imread(imagePath)\n",
    "\n",
    "def loadFilePointers(csvPath, dataset):\n",
    "    if not exists(csvPath):\n",
    "        raise Exception('File Not Found: ' + csvPath)\n",
    "    csv = pd.read_csv(csvPath)\n",
    "    return csv[csv[\"data set\"] == dataset]\n",
    "    \n",
    "def showDuplicateImages(set1ImagePaths, set2ImagePaths):\n",
    "    for idx in range(0, len(set1ImagePaths)):\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        ax1 = fig.add_subplot(idx+1, idx+2, 1)\n",
    "        imgplot1 = plt.imshow(mpimg.imread(set1ImagePaths[idx]))\n",
    "        ax1.set_title(set1ImagePaths[idx])\n",
    "        ax2 = fig.add_subplot(idx+1, idx+2, 2)\n",
    "        imgplot2 = plt.imshow(mpimg.imread(set2ImagePaths[idx]))\n",
    "        ax2.set_title(set2ImagePaths[idx])\n",
    "        plt.show()\n",
    "        \n",
    "def remove_bad_images(folder_path):\n",
    "    num_skipped = 0\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # Delete corrupted image\n",
    "            os.remove(fpath)\n",
    "            print(f'Removed: {fpath}')\n",
    "    if num_skipped > 0:\n",
    "        print(f'Total Removed: {num_skipped}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b555535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"train\"):\n",
    "    for subdir in dirs:\n",
    "        remove_bad_images(os.path.join(PROJECT_DATA_PATH + \"train\", subdir))\n",
    "        \n",
    "for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"valid\"):\n",
    "    for subdir in dirs:\n",
    "        remove_bad_images(os.path.join(PROJECT_DATA_PATH + \"valid\", subdir))\n",
    "\n",
    "for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"test\"):\n",
    "    for subdir in dirs:\n",
    "        remove_bad_images(os.path.join(PROJECT_DATA_PATH + \"test\", subdir))\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa1af7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47332 files belonging to 325 classes.\n",
      "Found 1625 files belonging to 325 classes.\n",
      "Train has 325 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PROJECT_DATA_PATH + \"train\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    PROJECT_DATA_PATH + \"valid\",\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "num_classes = train_ds.element_spec[1].shape[1]\n",
    "print(f'Train has {num_classes} classes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df12d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger(object):\n",
    "    \"\"\"Redirect stderr to stdout, optionally print stdout to a file, and \n",
    "    optionally force flushing on both stdout and the file.\"\"\"\n",
    "\n",
    "    def __init__(self, file_name: str = None, file_mode: str = \"w\", should_flush: bool = True):\n",
    "        self.file = None\n",
    "\n",
    "        if file_name is not None:\n",
    "            self.file = open(file_name, file_mode)\n",
    "\n",
    "        self.should_flush = should_flush\n",
    "        self.stdout = sys.stdout\n",
    "        self.stderr = sys.stderr\n",
    "\n",
    "        sys.stdout = self\n",
    "        sys.stderr = self\n",
    "\n",
    "    def __enter__(self) -> \"Logger\":\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type: Any, exc_value: Any, traceback: Any) -> None:\n",
    "        self.close()\n",
    "\n",
    "    def write(self, text: str) -> None:\n",
    "        \"\"\"Write text to stdout (and a file) and optionally flush.\"\"\"\n",
    "        if len(text) == 0: \n",
    "            return\n",
    "\n",
    "        if self.file is not None:\n",
    "            self.file.write(text)\n",
    "\n",
    "        self.stdout.write(text)\n",
    "\n",
    "        if self.should_flush:\n",
    "            self.flush()\n",
    "\n",
    "    def flush(self) -> None:\n",
    "        \"\"\"Flush written text to both stdout and a file, if open.\"\"\"\n",
    "        if self.file is not None:\n",
    "            self.file.flush()\n",
    "\n",
    "        self.stdout.flush()\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Flush, close possible files, and remove stdout/stderr mirroring.\"\"\"\n",
    "        self.flush()\n",
    "\n",
    "        # if using multiple loggers, prevent closing in wrong order\n",
    "        if sys.stdout is self:\n",
    "            sys.stdout = self.stdout\n",
    "        if sys.stderr is self:\n",
    "            sys.stderr = self.stderr\n",
    "\n",
    "        if self.file is not None:\n",
    "            self.file.close()\n",
    "\n",
    "\n",
    "class MyModelCheckpoint(ModelCheckpoint):\n",
    "  def __init__(self, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    super().on_epoch_end(epoch,logs)\n",
    "    \n",
    "    print(f'Epoch: {epoch}')\n",
    "    if logs == None:\n",
    "        tLogs = {'val_loss': 1.0, 'val_accuracy': 1.0, 'accuracy': 0.0, 'loss': 0.0}\n",
    "    else:\n",
    "        tLogs = logs\n",
    "    print(tLogs)\n",
    "    \n",
    "    # Also save the optimizer state\n",
    "    filepath = self._get_file_path(epoch, batch=None, logs=tLogs)\n",
    "    filepath = filepath.rsplit( \".\", 1 )[ 0 ] \n",
    "    filepath += \".pkl\"\n",
    "\n",
    "    with open(filepath, 'wb') as fp:\n",
    "      pickle.dump(\n",
    "        {\n",
    "          'opt': model.optimizer.get_config(),\n",
    "          'epoch': epoch+1\n",
    "         # Add additional keys if you need to store more values\n",
    "        }, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('\\nEpoch %05d: saving optimizaer to %s' % (epoch + 1, filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bcedbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "#model building\n",
    "def make_model(input_shape, num_classes):\n",
    "    base = EfficientNetV2B0(weights=\"imagenet\", include_top=False, input_shape=input_shape, classifier_activation=\"softmax\") #keras.Input(shape=input_shape)\n",
    "    model = models.Sequential()\n",
    "    model.add(base)\n",
    "    model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "    #model.add(data_augmentation)\n",
    "    #avoid overfitting\n",
    "    model.add(layers.Dropout(0.2, name=\"dropout_out\"))\n",
    "    # Set NUMBER_OF_CLASSES to the number of your final predictions.\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\", name=\"fc_out\"))\n",
    "    base.trainable = False\n",
    "    return 0, model, keras.optimizers.Adam(1e-3).get_config()\n",
    "\n",
    "def load_model_data(model_path, opt_path):\n",
    "    model = load_model(model_path)\n",
    "    with open(opt_path, 'rb') as fp:\n",
    "      d = pickle.load(fp)\n",
    "      epoch = d['epoch']\n",
    "      opt = d['opt']\n",
    "      return epoch, model, opt\n",
    "    \n",
    "def train_model(model, initial_epoch=0, max_epochs=50):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    callbacks = [\n",
    "        MyModelCheckpoint(\n",
    "            os.path.join(PROJECT_DATA_PATH + 'models/', 'model-{epoch:02d}-{val_loss:.2f}.hdf5'),\n",
    "            monitor='val_loss',verbose=0),\n",
    "    ]\n",
    "    \n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=max_epochs,\n",
    "        initial_epoch = initial_epoch,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=val_ds,\n",
    "    )\n",
    "\n",
    "    #score = model.evaluate(x_test, y_test, verbose=0, callbacks=cb)\n",
    "    #print('Test loss: {}'.format(score[0]))\n",
    "    #print('Test accuracy: {}'.format(score[1]))\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "696a2698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-01-0.40.hdf5\n"
     ]
    }
   ],
   "source": [
    "if exists(PROJECT_DATA_PATH + \"models\"):\n",
    "    for subdirs, dirs, files in os.walk(PROJECT_DATA_PATH + \"models\"):\n",
    "        for file in files:\n",
    "            print(file)\n",
    "else:\n",
    "    os.mkdir(PROJECT_DATA_PATH + \"models\")\n",
    "\n",
    "epoch, model, opt = make_model(input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3), num_classes=num_classes)\n",
    "#epoch, model, opt = load_model_data(model_path, opt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7539a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#keras.utils.plot_model(model, show_shapes=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam.from_config(opt),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a245e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 2.0788 - accuracy: 0.6768Epoch: 0\n",
      "{'loss': 2.0788252353668213, 'accuracy': 0.6767725944519043, 'val_loss': 0.4605654180049896, 'val_accuracy': 0.9027692079544067}\n",
      "\n",
      "Epoch 00001: saving optimizaer to ./Data/models\\model-01-0.46.pkl\n",
      "1480/1480 [==============================] - 1886s 1s/step - loss: 2.0788 - accuracy: 0.6768 - val_loss: 0.4606 - val_accuracy: 0.9028\n",
      "Epoch 2/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.7667 - accuracy: 0.8681Epoch: 1\n",
      "{'loss': 0.7667281627655029, 'accuracy': 0.868144154548645, 'val_loss': 0.3123959004878998, 'val_accuracy': 0.9372307658195496}\n",
      "\n",
      "Epoch 00002: saving optimizaer to ./Data/models\\model-02-0.31.pkl\n",
      "1480/1480 [==============================] - 1751s 1s/step - loss: 0.7667 - accuracy: 0.8681 - val_loss: 0.3124 - val_accuracy: 0.9372\n",
      "Epoch 3/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.8996Epoch: 2\n",
      "{'loss': 0.6020089983940125, 'accuracy': 0.8995816707611084, 'val_loss': 0.39352428913116455, 'val_accuracy': 0.9366154074668884}\n",
      "\n",
      "Epoch 00003: saving optimizaer to ./Data/models\\model-03-0.39.pkl\n",
      "1480/1480 [==============================] - 1788s 1s/step - loss: 0.6020 - accuracy: 0.8996 - val_loss: 0.3935 - val_accuracy: 0.9366\n",
      "Epoch 4/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.9162Epoch: 3\n",
      "{'loss': 0.5239557027816772, 'accuracy': 0.9161877632141113, 'val_loss': 0.38809603452682495, 'val_accuracy': 0.9415384531021118}\n",
      "\n",
      "Epoch 00004: saving optimizaer to ./Data/models\\model-04-0.39.pkl\n",
      "1480/1480 [==============================] - 1814s 1s/step - loss: 0.5240 - accuracy: 0.9162 - val_loss: 0.3881 - val_accuracy: 0.9415\n",
      "Epoch 5/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.4613 - accuracy: 0.9285Epoch: 4\n",
      "{'loss': 0.4612785577774048, 'accuracy': 0.928505003452301, 'val_loss': 0.4253968894481659, 'val_accuracy': 0.94338458776474}\n",
      "\n",
      "Epoch 00005: saving optimizaer to ./Data/models\\model-05-0.43.pkl\n",
      "1480/1480 [==============================] - 1870s 1s/step - loss: 0.4613 - accuracy: 0.9285 - val_loss: 0.4254 - val_accuracy: 0.9434\n",
      "Epoch 6/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.3985 - accuracy: 0.9384Epoch: 5\n",
      "{'loss': 0.3985491096973419, 'accuracy': 0.938371479511261, 'val_loss': 0.34989914298057556, 'val_accuracy': 0.9526153802871704}\n",
      "\n",
      "Epoch 00006: saving optimizaer to ./Data/models\\model-06-0.35.pkl\n",
      "1480/1480 [==============================] - 1815s 1s/step - loss: 0.3985 - accuracy: 0.9384 - val_loss: 0.3499 - val_accuracy: 0.9526\n",
      "Epoch 7/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.9429Epoch: 6\n",
      "{'loss': 0.3806762099266052, 'accuracy': 0.9428927302360535, 'val_loss': 0.3710509240627289, 'val_accuracy': 0.947692334651947}\n",
      "\n",
      "Epoch 00007: saving optimizaer to ./Data/models\\model-07-0.37.pkl\n",
      "1480/1480 [==============================] - 1743s 1s/step - loss: 0.3807 - accuracy: 0.9429 - val_loss: 0.3711 - val_accuracy: 0.9477\n",
      "Epoch 8/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.3330 - accuracy: 0.9506Epoch: 7\n",
      "{'loss': 0.333019882440567, 'accuracy': 0.9506465196609497, 'val_loss': 0.46172159910202026, 'val_accuracy': 0.947692334651947}\n",
      "\n",
      "Epoch 00008: saving optimizaer to ./Data/models\\model-08-0.46.pkl\n",
      "1480/1480 [==============================] - 1739s 1s/step - loss: 0.3330 - accuracy: 0.9506 - val_loss: 0.4617 - val_accuracy: 0.9477\n",
      "Epoch 9/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.9525Epoch: 8\n",
      "{'loss': 0.3256380259990692, 'accuracy': 0.9525268077850342, 'val_loss': 0.4549589455127716, 'val_accuracy': 0.9563077092170715}\n",
      "\n",
      "Epoch 00009: saving optimizaer to ./Data/models\\model-09-0.45.pkl\n",
      "1480/1480 [==============================] - 1745s 1s/step - loss: 0.3256 - accuracy: 0.9525 - val_loss: 0.4550 - val_accuracy: 0.9563\n",
      "Epoch 10/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.9576Epoch: 9\n",
      "{'loss': 0.29153740406036377, 'accuracy': 0.9576185345649719, 'val_loss': 0.337158739566803, 'val_accuracy': 0.9581538438796997}\n",
      "\n",
      "Epoch 00010: saving optimizaer to ./Data/models\\model-10-0.34.pkl\n",
      "1480/1480 [==============================] - 1910s 1s/step - loss: 0.2915 - accuracy: 0.9576 - val_loss: 0.3372 - val_accuracy: 0.9582\n",
      "Epoch 11/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2862 - accuracy: 0.9596Epoch: 10\n",
      "{'loss': 0.2861923575401306, 'accuracy': 0.9595833420753479, 'val_loss': 0.37782907485961914, 'val_accuracy': 0.9612307548522949}\n",
      "\n",
      "Epoch 00011: saving optimizaer to ./Data/models\\model-11-0.38.pkl\n",
      "1480/1480 [==============================] - 1832s 1s/step - loss: 0.2862 - accuracy: 0.9596 - val_loss: 0.3778 - val_accuracy: 0.9612\n",
      "Epoch 12/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9631Epoch: 11\n",
      "{'loss': 0.2599456310272217, 'accuracy': 0.9630693793296814, 'val_loss': 0.2783679664134979, 'val_accuracy': 0.9593846201896667}\n",
      "\n",
      "Epoch 00012: saving optimizaer to ./Data/models\\model-12-0.28.pkl\n",
      "1480/1480 [==============================] - 1773s 1s/step - loss: 0.2599 - accuracy: 0.9631 - val_loss: 0.2784 - val_accuracy: 0.9594\n",
      "Epoch 13/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2438 - accuracy: 0.9656Epoch: 12\n",
      "{'loss': 0.24384482204914093, 'accuracy': 0.9655835628509521, 'val_loss': 0.44809815287590027, 'val_accuracy': 0.9569230675697327}\n",
      "\n",
      "Epoch 00013: saving optimizaer to ./Data/models\\model-13-0.45.pkl\n",
      "1480/1480 [==============================] - 1771s 1s/step - loss: 0.2438 - accuracy: 0.9656 - val_loss: 0.4481 - val_accuracy: 0.9569\n",
      "Epoch 14/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.9660Epoch: 13\n",
      "{'loss': 0.24418310821056366, 'accuracy': 0.9659849405288696, 'val_loss': 0.4045245945453644, 'val_accuracy': 0.9599999785423279}\n",
      "\n",
      "Epoch 00014: saving optimizaer to ./Data/models\\model-14-0.40.pkl\n",
      "1480/1480 [==============================] - 1766s 1s/step - loss: 0.2442 - accuracy: 0.9660 - val_loss: 0.4045 - val_accuracy: 0.9600\n",
      "Epoch 15/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.9672Epoch: 14\n",
      "{'loss': 0.24365702271461487, 'accuracy': 0.9672103524208069, 'val_loss': 0.47386103868484497, 'val_accuracy': 0.9575384855270386}\n",
      "\n",
      "Epoch 00015: saving optimizaer to ./Data/models\\model-15-0.47.pkl\n",
      "1480/1480 [==============================] - 1765s 1s/step - loss: 0.2437 - accuracy: 0.9672 - val_loss: 0.4739 - val_accuracy: 0.9575\n",
      "Epoch 16/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.9699Epoch: 15\n",
      "{'loss': 0.23047439754009247, 'accuracy': 0.9698724150657654, 'val_loss': 0.3717840313911438, 'val_accuracy': 0.9618461728096008}\n",
      "\n",
      "Epoch 00016: saving optimizaer to ./Data/models\\model-16-0.37.pkl\n",
      "1480/1480 [==============================] - 1749s 1s/step - loss: 0.2305 - accuracy: 0.9699 - val_loss: 0.3718 - val_accuracy: 0.9618\n",
      "Epoch 17/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.9709Epoch: 16\n",
      "{'loss': 0.21824593842029572, 'accuracy': 0.9709287881851196, 'val_loss': 0.3695986270904541, 'val_accuracy': 0.9643076658248901}\n",
      "\n",
      "Epoch 00017: saving optimizaer to ./Data/models\\model-17-0.37.pkl\n",
      "1480/1480 [==============================] - 1757s 1s/step - loss: 0.2182 - accuracy: 0.9709 - val_loss: 0.3696 - val_accuracy: 0.9643\n",
      "Epoch 18/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9710Epoch: 17\n",
      "{'loss': 0.23039284348487854, 'accuracy': 0.9710344076156616, 'val_loss': 0.423445463180542, 'val_accuracy': 0.9612307548522949}\n",
      "\n",
      "Epoch 00018: saving optimizaer to ./Data/models\\model-18-0.42.pkl\n",
      "1480/1480 [==============================] - 1749s 1s/step - loss: 0.2304 - accuracy: 0.9710 - val_loss: 0.4234 - val_accuracy: 0.9612\n",
      "Epoch 19/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9737Epoch: 18\n",
      "{'loss': 0.2036978304386139, 'accuracy': 0.9736542105674744, 'val_loss': 0.32410451769828796, 'val_accuracy': 0.9692307710647583}\n",
      "\n",
      "Epoch 00019: saving optimizaer to ./Data/models\\model-19-0.32.pkl\n",
      "1480/1480 [==============================] - 1760s 1s/step - loss: 0.2037 - accuracy: 0.9737 - val_loss: 0.3241 - val_accuracy: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.9737Epoch: 19\n",
      "{'loss': 0.21973083913326263, 'accuracy': 0.9737175703048706, 'val_loss': 0.4348394274711609, 'val_accuracy': 0.9673846364021301}\n",
      "\n",
      "Epoch 00020: saving optimizaer to ./Data/models\\model-20-0.43.pkl\n",
      "1480/1480 [==============================] - 1760s 1s/step - loss: 0.2197 - accuracy: 0.9737 - val_loss: 0.4348 - val_accuracy: 0.9674\n",
      "Epoch 21/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.9760Epoch: 20\n",
      "{'loss': 0.19937677681446075, 'accuracy': 0.9759570956230164, 'val_loss': 0.36744675040245056, 'val_accuracy': 0.9643076658248901}\n",
      "\n",
      "Epoch 00021: saving optimizaer to ./Data/models\\model-21-0.37.pkl\n",
      "1480/1480 [==============================] - 1755s 1s/step - loss: 0.1994 - accuracy: 0.9760 - val_loss: 0.3674 - val_accuracy: 0.9643\n",
      "Epoch 22/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9765Epoch: 21\n",
      "{'loss': 0.1953829824924469, 'accuracy': 0.9764641523361206, 'val_loss': 0.49619853496551514, 'val_accuracy': 0.962461531162262}\n",
      "\n",
      "Epoch 00022: saving optimizaer to ./Data/models\\model-22-0.50.pkl\n",
      "1480/1480 [==============================] - 1792s 1s/step - loss: 0.1954 - accuracy: 0.9765 - val_loss: 0.4962 - val_accuracy: 0.9625\n",
      "Epoch 23/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.1915 - accuracy: 0.9761Epoch: 22\n",
      "{'loss': 0.19147291779518127, 'accuracy': 0.9760627150535583, 'val_loss': 0.3501776158809662, 'val_accuracy': 0.9704615473747253}\n",
      "\n",
      "Epoch 00023: saving optimizaer to ./Data/models\\model-23-0.35.pkl\n",
      "1480/1480 [==============================] - 1872s 1s/step - loss: 0.1915 - accuracy: 0.9761 - val_loss: 0.3502 - val_accuracy: 0.9705\n",
      "Epoch 24/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.1891 - accuracy: 0.9772Epoch: 23\n",
      "{'loss': 0.18910335004329681, 'accuracy': 0.9772036075592041, 'val_loss': 0.3097859025001526, 'val_accuracy': 0.9698461294174194}\n",
      "\n",
      "Epoch 00024: saving optimizaer to ./Data/models\\model-24-0.31.pkl\n",
      "1480/1480 [==============================] - 1890s 1s/step - loss: 0.1891 - accuracy: 0.9772 - val_loss: 0.3098 - val_accuracy: 0.9698\n",
      "Epoch 25/50\n",
      "1480/1480 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9771Epoch: 24\n",
      "{'loss': 0.19267414510250092, 'accuracy': 0.9770768284797668, 'val_loss': 0.43446341156959534, 'val_accuracy': 0.9661538600921631}\n",
      "\n",
      "Epoch 00025: saving optimizaer to ./Data/models\\model-25-0.43.pkl\n",
      "1480/1480 [==============================] - 1911s 1s/step - loss: 0.1927 - accuracy: 0.9771 - val_loss: 0.4345 - val_accuracy: 0.9662\n",
      "Epoch 26/50\n",
      " 237/1480 [===>..........................] - ETA: 26:07 - loss: 0.2087 - accuracy: 0.9775"
     ]
    }
   ],
   "source": [
    "if not exists(PROJECT_DATA_PATH + \"logs\"):\n",
    "    os.mkdir(PROJECT_DATA_PATH + \"logs\")\n",
    "    \n",
    "with Logger(os.path.join(PROJECT_DATA_PATH + 'logs', 'log.txt')):\n",
    "    train_model(model, initial_epoch=epoch, max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce23def",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    PROJECT_DATA_PATH + \"test/BELTED KINGFISHER/4.jpg\", target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0]\n",
    "print(\n",
    "    \"This image is %.2f percent cat and %.2f percent dog.\"\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
